{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importación y transformación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Ficheros Best players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos los ficheros CSV y los agrupamos en un mismo df\n",
    "\n",
    "directory = r'Datasets\\Best Players'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "        dataframes.append(df)\n",
    "\n",
    "best_players_raw = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "output_path = r'Datasets\\Best Players\\best_players_raw.csv'\n",
    "\n",
    "best_players_raw.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no necesitamos para el análisis\n",
    "\n",
    "best_players_raw = best_players_raw.drop(['Unnamed: 8','Unnamed: 15','Finish','SRS','Pace','Rel Pace','ORtg','Rel ORtg','DRtg','Rel DRtg','Coaches'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos un signo que no es necesario\n",
    "\n",
    "best_players_raw['Team'] = best_players_raw['Team'].str.replace('*', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos la columna en questión para trabajar mejor con los datos\n",
    "\n",
    "best_players_raw[['Player', 'WS']] = best_players_raw['Top WS'].str.split('(', expand=True)\n",
    "\n",
    "best_players_raw['WS'] = best_players_raw['WS'].str.rstrip(')')\n",
    "\n",
    "best_players_raw = best_players_raw.drop(['Top WS'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una nueva columna para trabajar mejor con los datos\n",
    "\n",
    "best_players_raw.rename(columns={'Playoffs': 'Playoffs Clasification'}, inplace=True)\n",
    "\n",
    "best_players_raw['Playoff'] = np.where(best_players_raw['Playoffs Clasification'].isna(), 'No', 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos valores nulos\n",
    "null_counts = best_players_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el DataFrame como un archivo CSV\n",
    "\n",
    "df = best_players_raw\n",
    "\n",
    "output_path = \"best_players.csv\" \n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Draft Picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos los ficheros CSV y los agrupamos en un mismo df\n",
    "\n",
    "directory = r'Datasets\\Draft Picks'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "        df['filename'] = filename[:-4]\n",
    "        dataframes.append(df)\n",
    "\n",
    "\n",
    "draft_picks_raw = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "output_path = r'Datasets\\Draft Picks\\draft_picks_raw.csv'\n",
    "\n",
    "draft_picks_raw.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_picks_raw = pd.read_csv(r'Datasets\\Draft Picks\\draft_picks_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos el .0 de Year\n",
    "draft_picks_raw['Year'] = draft_picks_raw['Year'].astype(str).str.replace('.0', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos ligas anteriores a NBA\n",
    "draft_picks_raw = draft_picks_raw.loc[~draft_picks_raw['Lg'].isin(['BAA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no necesitamos para el análisis\n",
    "draft_picks_raw = draft_picks_raw.drop(['Lg','BPM','WS/48','VORP'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiamos los nulos\n",
    "draft_picks_raw['College'] = draft_picks_raw['College'].fillna('Out US')\n",
    "draft_picks_raw = draft_picks_raw.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiamos variable Rd\n",
    "draft_picks_raw['Rd'] = draft_picks_raw['Rd'] .str.replace('[T]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas de jugadores que no han disputado ningún partido\n",
    "draft_picks_raw = draft_picks_raw[draft_picks_raw['G'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas de jugadores que en 1952-1953 no fueron drafteados y están incluidos\n",
    "draft_picks_raw = draft_picks_raw[draft_picks_raw['Pk'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos algunos valores en enteros\n",
    "draft_picks_raw[['Rd','Pk','G', 'MP', 'PTS', 'TRB', 'AST']] = draft_picks_raw[['Rd','Pk','G', 'MP', 'PTS', 'TRB', 'AST']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos los nombres de algunas variables\n",
    "draft_picks_raw.rename(columns={\n",
    "                                'Pk': 'Pick',\n",
    "                                'Rd': 'Round',\n",
    "                                'filename':'Team', \n",
    "                                'G': 'Games',\n",
    "                                'MP': 'Minutes Played',\n",
    "                                'MP.1': 'Minutes Played per game',\n",
    "                                'PTS.1': 'PTS per game',\n",
    "                                'TRB.1': 'TBR per game',\n",
    "                                'AST.1': 'AST per game',}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove (↳GSW) from player names\n",
    "def remove_team_initials(player_name):\n",
    "    if isinstance(player_name, str):\n",
    "        return player_name.split(' (↳')[0]\n",
    "    else:\n",
    "        return player_name  # Return as-is for non-string types\n",
    "\n",
    "# Apply the function to the 'player' column\n",
    "draft_picks_raw['Player'] = draft_picks_raw['Player'].apply(remove_team_initials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_picks_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el DataFrame como un archivo CSV\n",
    "\n",
    "df = draft_picks_raw\n",
    "\n",
    "output_path = \"draft_picks.csv\" \n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Algunos equipos no aparecen en el dataset como Baltimore Bullets, de los 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Payroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Assuming your CSV file is named 'data.csv'\n",
    "file_path = r'Datasets\\Payroll\\NBA Salary Cap History.csv'\n",
    "\n",
    "# Specify the delimiter as '\\t' (tab character)\n",
    "delimiter = '\\t'\n",
    "\n",
    "# Manually define headers\n",
    "headers = ['Year', 'Salary', 'Salary Adjusted to Year 2022']\n",
    "\n",
    "# Initialize an empty list to store rows from the CSV\n",
    "data = []\n",
    "\n",
    "# Open the CSV file and read its contents using csv.reader\n",
    "with open(file_path, 'r', newline='') as file:\n",
    "    reader = csv.reader(file, delimiter=delimiter)\n",
    "    \n",
    "    # Skip the header row from the file\n",
    "    next(reader)\n",
    "    \n",
    "    # Read remaining rows\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos en un valor numérico\n",
    "df['Salary'] = df['Salary'].str.replace('[\\$,]', '', regex=True).astype(float)\n",
    "df['Salary Adjusted to Year 2022'] = df['Salary Adjusted to Year 2022'].str.replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_to_update = ['2022-23', '2023-24']\n",
    "\n",
    "\n",
    "for year in years_to_update:\n",
    "    mask = df['Year'] == year\n",
    "    df.loc[mask, 'Salary Adjusted to Year 2022'] = df.loc[mask, 'Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos la variable año para que se represente correctamente\n",
    "def extract_year(year_str):\n",
    "    return year_str.split('-')[0]\n",
    "\n",
    "df['Year'] = df['Year'].apply(extract_year)\n",
    "df['Year'] = df['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"NBA_Salary_History.csv\" \n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Payroll 2023-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_payroll= pd.read_csv(r'Datasets\\Payroll\\2023-2024.csv')\n",
    "df_players= pd.read_csv(r'Datasets Cleaned\\player_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos los nombres de algunas variables\n",
    "df_payroll.rename(columns={'2023-24': 'Salary','Tm': 'Team'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos en un valor numérico\n",
    "df_payroll['Salary'] = df_payroll['Salary'].str.replace('[\\$,]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024 = df_players[df_players['Season'] == '2023-24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acotamos las columnas de la base de datos  para centrarnos en las variables que se pueden aportar más información útil y agrupamos Datasets\n",
    "target_columns = ['Player','Salary', 'Team']\n",
    "df_2024 = pd.merge(df_2024, df_payroll[target_columns], on='Player', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Player     0\n",
       "Pos        0\n",
       "Age        0\n",
       "G          0\n",
       "MP         0\n",
       "FG         0\n",
       "FGA        0\n",
       "FG%        0\n",
       "3P         0\n",
       "3PA        0\n",
       "3P%        0\n",
       "2P         0\n",
       "2PA        0\n",
       "2P%        0\n",
       "FT         0\n",
       "FTA        0\n",
       "FT%        0\n",
       "ORB        0\n",
       "DRB        0\n",
       "TRB        0\n",
       "AST        0\n",
       "STL        0\n",
       "BLK        0\n",
       "TOV        0\n",
       "PF         0\n",
       "PTS        0\n",
       "OWS        0\n",
       "DWS        0\n",
       "WS         0\n",
       "Season     0\n",
       "Salary    96\n",
       "Team      91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hay valores nulos en Salary por lo que aplicamos KNN\n",
    "df_2024 .isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de k: 4\n"
     ]
    }
   ],
   "source": [
    "def knn(df, columna_objetivo, min_k=2, max_k=15):\n",
    "    \"\"\"\n",
    "    Dado un DataFrame de pandas, el nombre de una columna objetivo, un rango de valores k y un\n",
    "    número mínimo de muestras por pliegue, realiza una regresión K-NN usando validación cruzada\n",
    "    para encontrar el mejor valor de k (número de vecinos) basado en el error cuadrático medio.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: DataFrame de pandas\n",
    "    - columna_objetivo: str, nombre de la columna objetivo\n",
    "    - min_k: int, número mínimo de vecinos a considerar\n",
    "    - max_k: int, número máximo de vecinos a considerar\n",
    "    \n",
    "    Retorna:\n",
    "    - mejor_k: int, mejor valor de k encontrado\n",
    "    \"\"\"\n",
    "    #Instanciar un objeto LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    #Hacer una copia del DataFrame de entrada\n",
    "    df_encoded = df.copy()\n",
    "    #Seleccionar columnas de tipo objeto (categóricas) del df_encoded\n",
    "    columnas_objeto = df_encoded.select_dtypes(include=[\"object\"]).columns\n",
    "    #Iterar sobre cada columna categórica y aplicar codificación de etiquetas\n",
    "    for columna in columnas_objeto:\n",
    "        df_encoded[columna] = le.fit_transform(df_encoded[columna].astype(str))\n",
    "    #Imputar valores faltantes usando la media de cada columna\n",
    "    imputador = SimpleImputer(strategy=\"mean\")\n",
    "    df_imputed = pd.DataFrame(\n",
    "        imputador.fit_transform(df_encoded), columns=df_encoded.columns\n",
    "    )\n",
    "    #Separar los predictores (X) del objetivo (y)\n",
    "    X = df_imputed.drop(columna_objetivo, axis=1)\n",
    "    y = df_imputed[columna_objetivo]\n",
    "    #Definir una tubería para la regresión K-NN\n",
    "    pipeline = Pipeline(steps=[(\"modelo\", KNeighborsRegressor(n_neighbors=3))])\n",
    "    #Establecer los hiperparámetros a afinar\n",
    "    parametros = {\n",
    "        \"modelo__n_neighbors\": [3, 5, 7],\n",
    "        \"modelo__weights\": [\"uniform\", \"distance\"],\n",
    "    }\n",
    "    mejor_k = 0\n",
    "    mejor_puntaje = -np.inf\n",
    "    #Iterar sobre un rango de valores k y realizar validación cruzada\n",
    "    for k in range(min_k, max_k + 1):\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, parametros, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X, y)\n",
    "        #Mantener el mejor k y el mejor puntaje encontrados hasta ahora\n",
    "        if grid_search.best_score_ > mejor_puntaje:\n",
    "            mejor_puntaje = grid_search.best_score_\n",
    "            mejor_k = k\n",
    "    #Retornar el mejor valor de k encontrado\n",
    "    return mejor_k\n",
    "\n",
    "def imputar_valores_faltantes_con_knn(df, columna_objetivo, n_vecinos):\n",
    "    \"\"\"\n",
    "    Imputa valores faltantes en la columna objetivo especificada usando imputación KNN.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: DataFrame de pandas\n",
    "    - columna_objetivo: str, nombre de la columna objetivo\n",
    "    - n_vecinos: int, número de vecinos a usar para la imputación KNN\n",
    "    \n",
    "    Retorna:\n",
    "    - df_imputed: DataFrame de pandas con valores imputados\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    imputador = KNNImputer(n_neighbors=n_vecinos)\n",
    "    columnas_numericas = df_imputed.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    df_imputed[columnas_numericas] = imputador.fit_transform(df_imputed[columnas_numericas])\n",
    "    return df_imputed\n",
    "\n",
    "def tipo_de_datos_original(df_encoded, info_codificador):\n",
    "    \"\"\"\n",
    "    Dado un DataFrame de pandas que ha sido codificado con la función `knn` y el diccionario de información del codificador\n",
    "    devuelto por esa función, decodifica todas las columnas categóricas y retorna\n",
    "    una copia del DataFrame original con las columnas codificadas reemplazadas por sus valores originales.\n",
    "    Esta función reemplaza cualquier código que no esté en la lista original de etiquetas con -1.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df_encoded: DataFrame de pandas\n",
    "    - info_codificador: lista de diccionarios\n",
    "    \n",
    "    Retorna:\n",
    "    - df_decoded: DataFrame de pandas\n",
    "    \"\"\"\n",
    "    df_decoded = df_encoded.copy()  # Hacer una copia del DataFrame codificado\n",
    "\n",
    "    #Iterar sobre cada codificador en el diccionario info_codificador\n",
    "    for codificador in info_codificador:\n",
    "        columna = codificador[\"columna\"]\n",
    "        etiquetas = codificador[\"etiquetas\"]\n",
    "        le = LabelEncoder()  #Crear un nuevo LabelEncoder para la columna\n",
    "        le.classes_ = np.array(etiquetas)  #Establecer las etiquetas originales\n",
    "        \n",
    "        #Detectar -1 y convertir a NaN para la transformación inversa\n",
    "        mascara = df_decoded[columna] == -1\n",
    "        df_decoded[columna] = df_decoded[columna].where(~mascara, other=-1)\n",
    "        \n",
    "        #Transformar inversamente los valores no NaN\n",
    "        mascara_no_nan = df_decoded[columna] != -1\n",
    "        df_decoded.loc[mascara_no_nan, columna] = le.inverse_transform(df_decoded.loc[mascara_no_nan, columna].astype(int))\n",
    "        \n",
    "        #Convertir -1 de nuevo a NaN\n",
    "        df_decoded[columna] = df_decoded[columna].replace(-1, np.nan)\n",
    "\n",
    "    return df_decoded\n",
    "\n",
    "# Cargar tu conjunto de datos\n",
    "df_2024 \n",
    "\n",
    "# Encontrar el mejor valor de k para la imputación\n",
    "mejor_k = knn(df_2024, 'Salary', min_k=2, max_k=15)\n",
    "print(f'Mejor valor de k: {mejor_k}')\n",
    "\n",
    "# Imputar valores faltantes en la columna 'Salary' usando imputación KNN\n",
    "df_2024_salary = imputar_valores_faltantes_con_knn(df_2024, 'Salary', mejor_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Player     0\n",
       "Pos        0\n",
       "Age        0\n",
       "G          0\n",
       "MP         0\n",
       "FG         0\n",
       "FGA        0\n",
       "FG%        0\n",
       "3P         0\n",
       "3PA        0\n",
       "3P%        0\n",
       "2P         0\n",
       "2PA        0\n",
       "2P%        0\n",
       "FT         0\n",
       "FTA        0\n",
       "FT%        0\n",
       "ORB        0\n",
       "DRB        0\n",
       "TRB        0\n",
       "AST        0\n",
       "STL        0\n",
       "BLK        0\n",
       "TOV        0\n",
       "PF         0\n",
       "PTS        0\n",
       "OWS        0\n",
       "DWS        0\n",
       "WS         0\n",
       "Season     0\n",
       "Salary     0\n",
       "Team      91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2024_salary.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>Season</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>PF</td>\n",
       "      <td>24.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>0.501</td>\n",
       "      <td>26.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>4379527.0</td>\n",
       "      <td>NYK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0.521</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>32600060.0</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ochai Agbaji</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>62.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>4114200.0</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Santi Aldama</td>\n",
       "      <td>PF</td>\n",
       "      <td>23.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>106.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>2194200.0</td>\n",
       "      <td>MEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nickeil Alexander-Walker</td>\n",
       "      <td>SG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>131.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>4687500.0</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>PF</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>8638413.0</td>\n",
       "      <td>PHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Trae Young</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>175.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>40064220.0</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Omer Yurtseven</td>\n",
       "      <td>C</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>2800000.0</td>\n",
       "      <td>UTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>2019706.0</td>\n",
       "      <td>NOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1794.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>10933333.0</td>\n",
       "      <td>LAC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Player Pos   Age     G      MP     FG     FGA    FG%  \\\n",
       "0            Precious Achiuwa  PF  24.0  74.0  1624.0  235.0   469.0  0.501   \n",
       "1                 Bam Adebayo   C  26.0  71.0  2416.0  530.0  1017.0  0.521   \n",
       "2                Ochai Agbaji  SG  23.0  78.0  1641.0  178.0   433.0  0.411   \n",
       "3                Santi Aldama  PF  23.0  61.0  1618.0  247.0   568.0  0.435   \n",
       "4    Nickeil Alexander-Walker  SG  25.0  82.0  1921.0  236.0   538.0  0.439   \n",
       "..                        ...  ..   ...   ...     ...    ...     ...    ...   \n",
       "617            Thaddeus Young  PF  35.0  33.0   439.0   65.0   108.0  0.602   \n",
       "618                Trae Young  PG  25.0  54.0  1942.0  433.0  1008.0  0.430   \n",
       "619            Omer Yurtseven   C  25.0  48.0   545.0   99.0   184.0  0.538   \n",
       "620               Cody Zeller   C  31.0  43.0   320.0   26.0    62.0  0.419   \n",
       "621               Ivica Zubac   C  26.0  68.0  1794.0  337.0   519.0  0.649   \n",
       "\n",
       "        3P    3PA  ...   BLK    TOV     PF     PTS  OWS  DWS   WS   Season  \\\n",
       "0     26.0   97.0  ...  68.0   83.0  143.0   565.0  1.2  2.2  3.4  2023-24   \n",
       "1     15.0   42.0  ...  66.0  162.0  159.0  1367.0  2.9  4.3  7.2  2023-24   \n",
       "2     62.0  211.0  ...  44.0   64.0  117.0   455.0 -0.5  0.6  0.1  2023-24   \n",
       "3    106.0  304.0  ...  54.0   69.0   89.0   654.0  0.4  2.0  2.4  2023-24   \n",
       "4    131.0  335.0  ...  42.0   76.0  143.0   655.0  1.5  2.8  4.3  2023-24   \n",
       "..     ...    ...  ...   ...    ...    ...     ...  ...  ...  ...      ...   \n",
       "617    1.0    7.0  ...   5.0   15.0   49.0   137.0  0.9  0.4  1.3  2023-24   \n",
       "618  175.0  469.0  ...  11.0  235.0  109.0  1389.0  4.0  0.6  4.6  2023-24   \n",
       "619    5.0   24.0  ...  18.0   37.0   52.0   222.0  0.3  0.4  0.7  2023-24   \n",
       "620    1.0    3.0  ...   5.0   16.0   45.0    76.0  0.4  0.4  0.8  2023-24   \n",
       "621    0.0    0.0  ...  83.0   79.0  180.0   794.0  4.5  2.3  6.8  2023-24   \n",
       "\n",
       "         Salary  Team  \n",
       "0     4379527.0   NYK  \n",
       "1    32600060.0   MIA  \n",
       "2     4114200.0   TOR  \n",
       "3     2194200.0   MEM  \n",
       "4     4687500.0   MIN  \n",
       "..          ...   ...  \n",
       "617   8638413.0   PHO  \n",
       "618  40064220.0   ATL  \n",
       "619   2800000.0   UTA  \n",
       "620   2019706.0   NOP  \n",
       "621  10933333.0   LAC  \n",
       "\n",
       "[622 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2024_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hay valores nulos en Team, decidimos eliminarlos ya que juegan en la G Leage con contratos duales, o casos como Jontay Porter vetado de la liga profesional\n",
    "df_2024_salary = df_2024_salary.dropna(subset=['Team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"salary_2024.csv\" \n",
    "\n",
    "df_2024_salary.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Team Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos los ficheros CSV y los agrupamos en un mismo df\n",
    "\n",
    "directory = r'Datasets\\Team Stats'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "        df['filename'] = filename[:-4]\n",
    "        dataframes.append(df)\n",
    "\n",
    "\n",
    "Team_stats_raw = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "output_path = r'Datasets\\Team Stats\\Team_stats_raw.csv'\n",
    "\n",
    "Team_stats_raw.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos ligas anteriores a NBA\n",
    "Team_stats_raw = Team_stats_raw.loc[~Team_stats_raw['Lg'].isin(['BAA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no necesitamos para el análisis\n",
    "Team_stats_raw = Team_stats_raw.drop(['Unnamed: 6','Unnamed: 10','G'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos los nombres de algunas variables\n",
    "Team_stats_raw.rename(columns={'Tm': 'Original Team Name', \n",
    "                                'filename': 'Current Team Name',\n",
    "                                'Finish': 'Position Regular Season',\n",
    "                                'Age': 'Average Player Age',\n",
    "                                'Ht.': 'Average Player Height',\n",
    "                                'Wt.': 'Average Player Weight',\n",
    "                                'G': 'TBR per game'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraermos el año inicial de la temporada y los convertimos a entero, luego eliminamos filas donde el año es menor a 1979\n",
    "df['Season'] = df['Season'].str[:4].astype(int)\n",
    "\n",
    "df = df[df['Season'] >= 1979]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el DataFrame como un archivo CSV\n",
    "\n",
    "df = Team_stats_raw \n",
    "\n",
    "output_path = \"team_stats.csv\" \n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Datasets\\Team Advanced Stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nos quedamos con la información de los estadios\n",
    "columnas_deseadas = ['Arena', 'Attend.', 'Attend./G']\n",
    "df = df[columnas_deseadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la fila total\n",
    "df = df.dropna(subset=['Arena'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el DataFrame como un archivo CSV\n",
    "\n",
    "output_path = \"arena.csv\" \n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Player Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024 = pd.read_csv(r'Datasets\\Player Stats\\2023-24 NBA Player Stats.csv')\n",
    "df_2024_adv = pd.read_csv(r'Datasets\\Player Stats\\2023-24 NBA Player Stats ADV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no necesitamos para el análisis\n",
    "df_2024 = df_2024.drop(['Rk','Tm','GS','eFG%'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos los nulos\n",
    "df_2024.loc[df_2024['3P'] == 0, '3P%'] = 0\n",
    "df_2024.loc[df_2024['FT'] == 0, 'FT%'] = 0\n",
    "df_2024.loc[df_2024['2P'] == 0, '2P%'] = 0\n",
    "df_2024.loc[df_2024['FG'] == 0, 'FG%'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acotamos las columnas de la base de datos  para centrarnos en las variables que se pueden aportar más información útil y agrupamos Datasets\n",
    "target_columns = [\"Player-additional\", \"OWS\", \"DWS\", \"WS\"]\n",
    "df_2024 = pd.merge(df_2024, df_2024_adv[target_columns], on='Player-additional', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el DataFrame como un archivo CSV\n",
    "output_path = \"2023-24.csv\" \n",
    "df_2024.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos los ficheros CSV generados y los agrupamos en un mismo df\n",
    "\n",
    "directory = r'Datasets\\Player Stats\\Players'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "        df['filename'] = filename[:-4]\n",
    "        dataframes.append(df)\n",
    "\n",
    "\n",
    "players_stats_raw = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "output_path = 'players_stats_raw'\n",
    "\n",
    "players_stats_raw.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_stats_raw = pd.read_csv(r'Datasets\\Player Stats\\players_stats_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas que no necesitamos para el análisis\n",
    "players_stats_raw  = players_stats_raw.drop(['Player-additional'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos los nombres de algunas variables\n",
    "players_stats_raw.rename(columns={'filename': 'Season'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('SG-PG', 'SG')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('PF-SF', 'PF')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('SG-SF', 'SG')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('SF-PF', 'SF')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('PG-SG', 'PG')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('SF-SG', 'SF')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('PF-C', 'PF')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('SG-PF', 'SG')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('C-PF', 'C')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('SF-C', 'SF')\n",
    "players_stats_raw['Pos'] = players_stats_raw['Pos'].replace('SG-PG-SF', 'SG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el DataFrame como un archivo CSV\n",
    "output_path = \"player_stats.csv\" \n",
    "players_stats_raw.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
